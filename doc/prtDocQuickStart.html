
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Quick Start</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-12-13"><meta name="DC.source" content="prtDocQuickStart.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Quick Start</h1><!--introduction--><p>This document will quickly introduce you to a few basics of the PRT: data sets, classifiers, and algorithms.  For a more detailed outline of these topics, please see our <a href="http://www.newfolderconsulting.com/prtdoc/">documentation</a></p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Formatting Your Data (Making x and y)</a></li><li><a href="#2">Creating and Plotting Data Sets (Using x and y)</a></li><li><a href="#3">Actions</a></li><li><a href="#5">Classifiers</a></li><li><a href="#7">Combining Actions</a></li><li><a href="#8">Cross-Validation</a></li><li><a href="#11">More Information</a></li></ul></div><h2>Formatting Your Data (Making x and y)<a name="1"></a></h2><p>To use the PRT, data should be stored in prtDataSet objects.  The most important prtDataSet object is the basic classification data set - prtDataSetClass.</p><p>The simplest classification data sets assume that the data you are using is stored in a double matrix, and each row corresponds to an observation (or object), and each column corresponds to a feature (or variable). Furthermore, for a labeled data set, each observation should be drawn from one of N discrete classes, stored in a nObservations x 1 vector.</p><p>As convention, the data matrix is often referred to as "x", and the label vector is referred to as "y". For example, the following code makes x and y matrices for 2 classes, with 100 samples per class.</p><pre class="codeinput">nSamplesPerClass = 100;
nFeatures = 2;

mean_0 = 0;  <span class="comment">% The mean of class 0</span>
mean_1 = 2;  <span class="comment">% The mean of class 1</span>

<span class="comment">% x_0 will be a 2 dimensional Guassian distrbuted variable with mean [0 0]</span>
x_0 = randn(nSamplesPerClass,nFeatures) + mean_0;
<span class="comment">% y_0 correspond to the labels of x_0, in this case, class 0</span>
y_0 = zeros(nSamplesPerClass,1);

<span class="comment">% x_1 will be a 2 dimensional Guassian distrbuted variable with mean [2 2]</span>
x_1 = randn(nSamplesPerClass,nFeatures) + mean_1;
<span class="comment">% y_1 correspond to the labels of x_1, in this case, class 1</span>
y_1 = ones(nSamplesPerClass,1);

<span class="comment">% Concatenate both, now we have a vector of observations x, and a vector of</span>
<span class="comment">% corresponding class labels, y.</span>
x = [x_0;x_1];
y = [y_0;y_1];
</pre><h2>Creating and Plotting Data Sets (Using x and y)<a name="2"></a></h2><p>Given data like x and y from above, it's easy to make a prtDataSetClass from data and class labels, if your data is in a matrix x of size nObservations x nFeatures, and the labels are in a vector y of size nObservations x 1 (with y == 1 indicating class 1, and y == 0 indicating class 0, for example), just call:</p><pre class="codeinput">dataSet = prtDataSetClass(x,y);

<span class="comment">% The plot function is overloaded for prtDataSet objects:</span>
plot(dataSet);
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_01.png" alt=""> <h2>Actions<a name="3"></a></h2><p>prtActions represent the different types of operations you can apply to your data.</p><p>Almost everything you can do in the PRT is implemented as a prtAction, and all prtActions can be trained and run. Training is the activity of inferring parameters from a set of data (for example, training a PCA object consists of inferring the principal component loadings). Running an action results in applying the trained object to a set of data (for example, running a classifier object assigns confidences to each observation).</p><p>The input to a TRAIN method should be the data set to be used for training, and the output of training any action is an object of the same type as the original action, but with additional fields set based on the training data.</p><p>For a concrete example, consider the PRT implementation of principle component analysis, the prtPreProcPca object.  prtPreProcPca is a prtAction, so it has a train and a run method, and we can do the following:</p><pre class="codeinput">pca = prtPreProcPca;      <span class="comment">% Create a prtPreProcPca object</span>
pca.nComponents = 2;      <span class="comment">% nComponents is a field of prtPreProcPca objects</span>
pca = pca.train(dataSet); <span class="comment">% Outputs a pca object with pcaVectors set</span>
</pre><p>The RUN method can only be used on a prtAction object which has already been trained.  The RUN method takes in a new data set (the test data set), and outputs the results of processing the data set with the trained object.  For pre-processing objects, this results in a data set with observations that have been processed (e.g., by mapping to PCA scores).</p><p>For example:</p><pre class="codeinput">dataSetPca = pca.run(dataSet);    <span class="comment">% Run the trained object on the dataSet</span>

subplot(2,1,1); plot(dataSet);    title(<span class="string">'Original DataSet'</span>);
subplot(2,1,2); plot(dataSetPca); title(<span class="string">'PCA Processed DataSet'</span>);
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_02.png" alt=""> <h2>Classifiers<a name="5"></a></h2><p>Since classifiers are also implemented as prtActions, the exact same approach as above applies.  For example, say we want to train and evaluate a Fisher's linear discriminant classifier on our data.  We could do the following</p><pre class="codeinput">subplot(1,1,1); <span class="comment">%clear the previous two plots</span>

fld = prtClassFld;         <span class="comment">% Create a Fisher linear discriminant classifier</span>
fld = fld.train(dataSet);  <span class="comment">% Train it using the data set</span>
yOut = fld.run(dataSet);   <span class="comment">% Apply it to the data set</span>

<span class="comment">% We can plot the Receiver Operating Curve of the classifier, to give an</span>
<span class="comment">% indication of how well it is performing:</span>
prtScoreRoc(yOut);
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_03.png" alt=""> <p>Where we have made use of the prtScoreRoc method which evaluates the ROC curve for a binary data set.  Classifier objects also define a PLOT method, which can be used to visualize decision contours for trained classifiers (as long as the number of features in the data set is &lt;= 3)</p><pre class="codeinput">fld.plot;  <span class="comment">%equivalently, plot(fld)</span>
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_04.png" alt=""> <h2>Combining Actions<a name="7"></a></h2><p>Many different types of actions can be combined into more complicated actions.  This is easily accomplished using the + operator.  For example, to perform PCA, followed by FLD classification, use the + operator to concatenate a PCA and FLD object:</p><pre class="codeinput">pcaFldAlgorithm = prtPreProcPca(<span class="string">'nComponents'</span>,2) + prtClassFld;
<span class="comment">% Train and run as before</span>
pcaFldAlgorithm = pcaFldAlgorithm.train(dataSet);
yOut = pcaFldAlgorithm.run(dataSet);
prtScoreRoc(yOut);
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_05.png" alt=""> <h2>Cross-Validation<a name="8"></a></h2><p>In the examples above, we have performed training and testing on the exact same data set; this can often result in overly optimistic estimates of algorithm or classifier performance.  To remedy that, we might split our data into training and testing data, then use the training portion in calls to TRAIN, and the testing portion in the call to RUN.  However, this is somewhat wasteful of data, if we switched the data partition, we get a different, but equally valid measure of performance.</p><p>Cross-validation is a procedure for iteratively splitting the available data into different training/testing sets (referred to as "folds") such that all data is used for training and all data is used for testing in different iterations. Cross-validation enables more accurate estimates of algorithm performance than the simpler approaches described above.</p><p>Most prtActions can be cross-validated using one of two methods - KFOLDS or CROSSVALIDATE.</p><p>The KFOLDS method provides a simple utility to randomly split the available data into K folds, and aggregate results across all combinations of training on K-1 folds and testing on the remaining fold.</p><p>The inputs to the K-folds method are the data set to be used in cross-validation and the number of folds to use.  The output of the KFOLDS method is a data set containing the results of testing on each element in the input data set.</p><pre class="codeinput">fld = prtClassFld;              <span class="comment">% Create the data classifier</span>
yOut = fld.kfolds(dataSet,3);   <span class="comment">% Call KFOLDS with 3 folds</span>

<span class="comment">% Instead of plotting right away, we'll retain the data so we can overlay</span>
<span class="comment">% several ROC plots momentarily</span>
[pfFldKfolds,pdFldKfolds] = prtScoreRoc(yOut);
</pre><p>Note that since algorithms are also prtAction objects, KFOLDS works in the same manner:</p><pre class="codeinput"><span class="comment">% Create an algorithm</span>
pcaFldAlgorithm = prtPreProcPca(<span class="string">'nComponents'</span>,2) + prtClassFld;
<span class="comment">% Run KFOLDS with 10 folds</span>
yOut = pcaFldAlgorithm.kfolds(dataSet,10);
<span class="comment">% Evaluate the receiver operating curve</span>
[pfAlgoKfolds,pdAlgoKfolds] = prtScoreRoc(yOut);
</pre><p>Although K-folds is easy to use, sometimes we might want to exercise more control over what data is used in which training or evaluation fold. For example, we might want to ensure that neighboring observations are not used in the same folds.  The CROSSVALIDATE method enables the use to specify integer valued fold indices to define which data will be kept together in different folds.</p><pre class="codeinput"><span class="comment">% For example, make a repeating vector [0;1;2;0;1;2;...], so that every third</span>
<span class="comment">% observation is used in the same fold:</span>
foldLabels = mod(1:dataSet.nObservations,3)';

<span class="comment">% Call CROSSVALIDATE with the fold lables</span>
yOut = pcaFldAlgorithm.crossValidate(dataSet,foldLabels);
<span class="comment">% Evaluate the receiver operating curve</span>
[pfAlgoXval,pdAlgoXval] = prtScoreRoc(yOut);

<span class="comment">% Compare the three different techniques</span>
h = plot(pfFldKfolds,pdFldKfolds,pfAlgoKfolds,pdAlgoKfolds,pfAlgoXval,pdAlgoXval);
set(h,<span class="string">'linewidth'</span>,3);
legend(h,{<span class="string">'FLD Kfolds'</span>,<span class="string">'PCA+FLD Kfolds'</span>,<span class="string">'PCA+FLD X-Val'</span>});
</pre><img vspace="5" hspace="5" src="prtDocQuickStart_06.png" alt=""> <h2>More Information<a name="11"></a></h2><p>This is just a brief overview to help you get started with the PRT; additional information about all the objects described here can be found in <a href="prtDocGettingStartedExamples.html">Some examples of using the PRT</a></p><p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% Quick Start
% This document will quickly introduce you to a few basics of the PRT: data
% sets, classifiers, and algorithms.  For a more detailed outline of these
% topics, please see our <http://www.newfolderconsulting.com/prtdoc/
% documentation>
% 
%

%% Formatting Your Data (Making x and y)
% To use the PRT, data should be stored in prtDataSet objects.  The most
% important prtDataSet object is the basic classification data set -
% prtDataSetClass.
%
% The simplest classification data sets assume that the data you are using
% is stored in a double matrix, and each row corresponds to an observation
% (or object), and each column corresponds to a feature (or variable).
% Furthermore, for a labeled data set, each observation should be drawn
% from one of N discrete classes, stored in a nObservations x 1 vector.
%
% As convention, the data matrix is often referred to as "x", and the label
% vector is referred to as "y". For example, the following code makes x and
% y matrices for 2 classes, with 100 samples per class.

nSamplesPerClass = 100;
nFeatures = 2;

mean_0 = 0;  % The mean of class 0
mean_1 = 2;  % The mean of class 1

% x_0 will be a 2 dimensional Guassian distrbuted variable with mean [0 0]
x_0 = randn(nSamplesPerClass,nFeatures) + mean_0;
% y_0 correspond to the labels of x_0, in this case, class 0
y_0 = zeros(nSamplesPerClass,1);

% x_1 will be a 2 dimensional Guassian distrbuted variable with mean [2 2]
x_1 = randn(nSamplesPerClass,nFeatures) + mean_1;
% y_1 correspond to the labels of x_1, in this case, class 1
y_1 = ones(nSamplesPerClass,1);

% Concatenate both, now we have a vector of observations x, and a vector of
% corresponding class labels, y.
x = [x_0;x_1];
y = [y_0;y_1];

%% Creating and Plotting Data Sets (Using x and y)
% Given data like x and y from above, it's easy to make a prtDataSetClass
% from data and class labels, if your data is in a matrix x of size
% nObservations x nFeatures, and the labels are in a vector y of size
% nObservations x 1 (with y == 1 indicating class 1, and y == 0 indicating
% class 0, for example), just call:

dataSet = prtDataSetClass(x,y);

% The plot function is overloaded for prtDataSet objects:
plot(dataSet);

%% Actions
% prtActions represent the different types of operations you can apply to
% your data.
%
% Almost everything you can do in the PRT is implemented as a prtAction,
% and all prtActions can be trained and run. Training is the activity of
% inferring parameters from a set of data (for example, training a PCA
% object consists of inferring the principal component loadings). Running
% an action results in applying the trained object to a set of data (for
% example, running a classifier object assigns confidences to each observation).
%
% The input to a TRAIN method should be the data set to be used for
% training, and the output of training any action is an object of the same
% type as the original action, but with additional fields set based on the
% training data.
%
% For a concrete example, consider the PRT implementation of principle
% component analysis, the prtPreProcPca object.  prtPreProcPca is a
% prtAction, so it has a train and a run method, and we can do the
% following:

pca = prtPreProcPca;      % Create a prtPreProcPca object
pca.nComponents = 2;      % nComponents is a field of prtPreProcPca objects
pca = pca.train(dataSet); % Outputs a pca object with pcaVectors set

%% 
% The RUN method can only be used on a prtAction object which
% has already been trained.  The RUN method takes in a new data set (the
% test data set), and outputs the results of processing the data set with
% the trained object.  For pre-processing objects, this results in a data
% set with observations that have been processed (e.g., by mapping to PCA
% scores).
%
% For example:

dataSetPca = pca.run(dataSet);    % Run the trained object on the dataSet

subplot(2,1,1); plot(dataSet);    title('Original DataSet');
subplot(2,1,2); plot(dataSetPca); title('PCA Processed DataSet');

%% Classifiers
% Since classifiers are also implemented as prtActions, the exact same
% approach as above applies.  For example, say we want to train and
% evaluate a Fisher's linear discriminant classifier on our data.  We could
% do the following

subplot(1,1,1); %clear the previous two plots

fld = prtClassFld;         % Create a Fisher linear discriminant classifier
fld = fld.train(dataSet);  % Train it using the data set
yOut = fld.run(dataSet);   % Apply it to the data set

% We can plot the Receiver Operating Curve of the classifier, to give an
% indication of how well it is performing:
prtScoreRoc(yOut);

%%
% Where we have made use of the prtScoreRoc method which evaluates the ROC
% curve for a binary data set.  Classifier objects also define a PLOT
% method, which can be used to visualize decision contours for trained
% classifiers (as long as the number of features in the data set is <= 3)

fld.plot;  %equivalently, plot(fld)

%% Combining Actions
% Many different types of actions can be combined into more complicated
% actions.  This is easily accomplished using the + operator.  For example,
% to perform PCA, followed by FLD classification, use the + operator to
% concatenate a PCA and FLD object:

pcaFldAlgorithm = prtPreProcPca('nComponents',2) + prtClassFld;
% Train and run as before
pcaFldAlgorithm = pcaFldAlgorithm.train(dataSet);
yOut = pcaFldAlgorithm.run(dataSet);
prtScoreRoc(yOut);

%% Cross-Validation
% In the examples above, we have performed training and testing on the
% exact same data set; this can often result in overly optimistic estimates
% of algorithm or classifier performance.  To remedy that, we might split
% our data into training and testing data, then use the training portion in
% calls to TRAIN, and the testing portion in the call to RUN.  However,
% this is somewhat wasteful of data, if we switched the data partition, we
% get a different, but equally valid measure of performance.
%
% Cross-validation is a procedure for iteratively splitting the available
% data into different training/testing sets (referred to as "folds") such
% that all data is used for training and all data is used for testing in
% different iterations. Cross-validation enables more accurate estimates of
% algorithm performance than the simpler approaches described above.
%
% Most prtActions can be cross-validated using one of two methods - KFOLDS
% or CROSSVALIDATE.
%
% The KFOLDS method provides a simple utility to randomly split the
% available data into K folds, and aggregate results across all
% combinations of training on K-1 folds and testing on the remaining fold.
%
% The inputs to the K-folds method are the data set to be used in
% cross-validation and the number of folds to use.  The output of the
% KFOLDS method is a data set containing the results of testing on each
% element in the input data set.

fld = prtClassFld;              % Create the data classifier
yOut = fld.kfolds(dataSet,3);   % Call KFOLDS with 3 folds

% Instead of plotting right away, we'll retain the data so we can overlay
% several ROC plots momentarily
[pfFldKfolds,pdFldKfolds] = prtScoreRoc(yOut); 

%%
% Note that since algorithms are also prtAction objects, KFOLDS works in
% the same manner:

% Create an algorithm
pcaFldAlgorithm = prtPreProcPca('nComponents',2) + prtClassFld;
% Run KFOLDS with 10 folds
yOut = pcaFldAlgorithm.kfolds(dataSet,10);
% Evaluate the receiver operating curve
[pfAlgoKfolds,pdAlgoKfolds] = prtScoreRoc(yOut);

%%
% Although K-folds is easy to use, sometimes we might want to exercise more
% control over what data is used in which training or evaluation fold. For
% example, we might want to ensure that neighboring observations are not
% used in the same folds.  The CROSSVALIDATE method enables the use to
% specify integer valued fold indices to define which data will be kept
% together in different folds.  

% For example, make a repeating vector [0;1;2;0;1;2;...], so that every third
% observation is used in the same fold:
foldLabels = mod(1:dataSet.nObservations,3)';  

% Call CROSSVALIDATE with the fold lables
yOut = pcaFldAlgorithm.crossValidate(dataSet,foldLabels);
% Evaluate the receiver operating curve
[pfAlgoXval,pdAlgoXval] = prtScoreRoc(yOut);

% Compare the three different techniques
h = plot(pfFldKfolds,pdFldKfolds,pfAlgoKfolds,pdAlgoKfolds,pfAlgoXval,pdAlgoXval);
set(h,'linewidth',3);
legend(h,{'FLD Kfolds','PCA+FLD Kfolds','PCA+FLD X-Val'});

%% More Information
% This is just a brief overview to help you get started with the PRT;
% additional information about all the objects described here can be found
% in <prtDocGettingStartedExamples.html Some examples of using the PRT>
##### SOURCE END #####
--></body></html>